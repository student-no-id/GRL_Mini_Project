{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2293,"status":"ok","timestamp":1704865399823,"user":{"displayName":"Leo Bujdei-Leonte","userId":"14269380342128481548"},"user_tz":0},"id":"9YuF2gs2jlVy","outputId":"c86a5cf4-af43-4d22-fcd0-e5c3e2d6b409"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.1.0+cu121\n"]}],"source":["# Check PyTorch version installed on this system\n","!python -c \"import torch; print(torch.__version__)\""]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4468,"status":"ok","timestamp":1704865404286,"user":{"displayName":"Leo Bujdei-Leonte","userId":"14269380342128481548"},"user_tz":0},"id":"9oDStxemj2_U"},"outputs":[],"source":["%%capture\n","# Download the corresponding PyTorch Geometric module\n","\"\"\"\n","Assign to TORCH with what you get from the cell above. E.g., export TORCH=1.12.1+cu113\n","\"\"\"\n","%env TORCH=2.0.1+cu118\n","!pip install torch-geometric"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3291,"status":"ok","timestamp":1704865407566,"user":{"displayName":"Leo Bujdei-Leonte","userId":"14269380342128481548"},"user_tz":0},"id":"EjH-8cw4j5Ai","outputId":"eb56fd71-046a-4192-8b8d-d268bcc6b1bc"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["import random\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch_geometric.utils import from_networkx\n","import torch_geometric.utils as geom_utils\n","from torch_geometric.data import Data\n","from torch_geometric.loader import DataLoader\n","import torch_geometric.nn as geom_nn\n","import networkx as nx\n","import matplotlib.pyplot as plt\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":32,"status":"ok","timestamp":1704865407570,"user":{"displayName":"Leo Bujdei-Leonte","userId":"14269380342128481548"},"user_tz":0},"id":"pYakvoKBqZtH"},"outputs":[],"source":["class ClippedReLU(torch.autograd.Function):\n","  @staticmethod\n","  def forward(ctx, input):\n","    output = input.clone()\n","    input.clamp(min=-1, max=1)\n","    ctx.save_for_backward(input)\n","    return output\n","\n","  @staticmethod\n","  def backward(ctx, grad_output):\n","    input, = ctx.saved_tensors\n","    grad_input = grad_output.clone()\n","    grad_input[input < -1] = 0\n","    grad_input[input > 1] = 0\n","    return grad_input\n","\n","  # dtype = torch.float\n","  # device = torch.device(\"cpu\")\n","  # relu = ClippedReLU().apply"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":31,"status":"ok","timestamp":1704865407571,"user":{"displayName":"Leo Bujdei-Leonte","userId":"14269380342128481548"},"user_tz":0},"id":"TpEEISGJL2P3"},"outputs":[],"source":["class GCN(torch.nn.Module):\n","  def __init__(self, gcn_channels, num_gcn_layers, gcn_act, pooling,\n","               mlp_channels, num_mlp_layers, mlp_act,\n","               final_act, uniform_init=True):\n","    super(GCN, self).__init__()\n","    self.gcn = nn.ModuleList(\n","        [geom_nn.GCNConv(gcn_channels[0], gcn_channels[1], add_self_loops=True, normalize=False)] +\n","        [geom_nn.GCNConv(gcn_channels[1], gcn_channels[1], add_self_loops=True, normalize=False)\n","            for _ in range(num_gcn_layers-2)] +\n","        [geom_nn.GCNConv(gcn_channels[1], gcn_channels[-1], add_self_loops=True, normalize=False)]\n","    ) if num_gcn_layers > 1 else nn.ModuleList(\n","        [geom_nn.GCNConv(gcn_channels[0], gcn_channels[-1], add_self_loops=True, normalize=False)]\n","    )\n","    self.gcn_act = gcn_act\n","    self.pooling = pooling\n","\n","    self.mlp = nn.ModuleList(\n","        [nn.Linear(gcn_channels[-1], mlp_channels[0])] +\n","        [nn.Linear(mlp_channels[0], mlp_channels[0]) for _ in range(num_mlp_layers-2)] +\n","        [nn.Linear(mlp_channels[0], mlp_channels[-1])]\n","    ) if num_mlp_layers > 1 else nn.ModuleList(\n","        [nn.Linear(mlp_channels[0], mlp_channels[-1])]\n","    )\n","    self.mlp_act = mlp_act\n","    self.final_act = final_act\n","\n","    if  (uniform_init):\n","      for layer in self.gcn:\n","        nn.init.uniform_(layer.lin.weight, -1.0, 1.0)\n","        layer.lin.bias = nn.Parameter(torch.rand(1) * 2 - 1)\n","      for layer in self.mlp:\n","        nn.init.uniform_(layer.weight, -1.0, 1.0)\n","        layer.bias = nn.Parameter(torch.rand(1) * 2 - 1)\n","\n","  def forward(self, x, edge_index):\n","    for layer in self.gcn[:-1]:\n","      x = self.gcn_act(layer(x, edge_index))\n","    x = self.pooling(self.gcn[-1](x, edge_index), None)\n","\n","    for layer in self.mlp[:-1]:\n","      x = self.mlp_act(layer(x))\n","    x = self.final_act(self.mlp[-1](x))\n","\n","    return x"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1704865407571,"user":{"displayName":"Leo Bujdei-Leonte","userId":"14269380342128481548"},"user_tz":0},"id":"FBg7Zjr7zLYs","outputId":"bffd8c8e-7e84-4aa0-8e68-4beee53a39fa"},"outputs":[{"output_type":"stream","name":"stdout","text":["drive/MyDrive/GRL_Mini_Project/data/erdos_renyi/regular/graph_10_50000_10_0.pt\n","drive/MyDrive/GRL_Mini_Project/data/stochastic_block_model/few_dense_out/10/1.pt\n","drive/MyDrive/GRL_Mini_Project/data/barabasi_albert/very sparse/5/2.pt\n"]}],"source":["from enum import Enum\n","import os\n","from math import log\n","\n","GRAPHS_PATH = \"drive/MyDrive/GRL_Mini_Project/data\"\n","MIN_P = 100000\n","\n","subtype_probs = {\n","    \"regular\": lambda n: 0.5,\n","    \"sparse\": lambda n: log(n) / (10 * n),\n","    \"very_sparse\": lambda n: 1 / n,\n","}\n","\n","class GenerationMode(Enum):\n","  ER = \"erdos_renyi\"\n","  SBM = \"stochastic_block_model\"\n","  BA = \"barabasi_albert\"\n","\n","def graph_file_name(mode: GenerationMode, **kwargs):\n","  if mode == GenerationMode.ER:\n","    num_nodes = kwargs[\"num_nodes\"]\n","    p_edge = kwargs[\"p_edge\"]\n","    num_features = kwargs[\"num_features\"]\n","    idx = kwargs.get(\"idx\", \"0\")\n","    subtype = kwargs.get(\"subtype\", \"regular\")\n","\n","    if (p_edge < 1 / MIN_P):\n","      raise ValueError(f\"Cannot assign file name, probability {p} too small.\")\n","\n","    return os.sep.join([\n","        GRAPHS_PATH, \"erdos_renyi\", subtype, \"_\".join([\n","            \"graph\", str(num_nodes), str(int(p_edge * MIN_P)), str(num_features), str(idx)\n","        ]) + \".pt\"\n","    ])\n","\n","  elif mode == GenerationMode.SBM:\n","    num_nodes = kwargs[\"num_nodes\"]\n","    subtype = kwargs[\"subtype\"]\n","    idx = kwargs[\"idx\"]\n","\n","    return os.sep.join([\n","        GRAPHS_PATH, \"stochastic_block_model\", subtype, str(num_nodes), str(idx) + \".pt\"\n","    ])\n","\n","  elif mode == GenerationMode.BA:\n","    num_nodes = kwargs[\"num_nodes\"]\n","    subtype = kwargs[\"subtype\"]\n","    idx = kwargs[\"idx\"]\n","\n","    return os.sep.join([\n","        GRAPHS_PATH, \"barabasi_albert\", subtype, str(num_nodes), str(idx) + \".pt\"\n","    ])\n","\n","  else:\n","    raise ValueError(\"Cannot identify generation mode.\")\n","\n","print(graph_file_name(mode=GenerationMode.ER, num_nodes=10, p_edge=0.5, num_features=10))\n","print(graph_file_name(mode=GenerationMode.SBM, num_nodes=10, subtype=\"few_dense_out\", idx=1))\n","print(graph_file_name(mode=GenerationMode.BA, num_nodes=5, subtype=\"very sparse\", idx=2))"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1704865407572,"user":{"displayName":"Leo Bujdei-Leonte","userId":"14269380342128481548"},"user_tz":0},"id":"4cNWoByxltdI","outputId":"e0b56eb8-3572-4415-f232-4f9fe8913128"},"outputs":[{"output_type":"stream","name":"stdout","text":["drive/MyDrive/GRL_Mini_Project/models/uniform_init/10_10_10_2_3_clipped_relu_mean_3_1_2_tanh_sigmoid/1.pt\n"]}],"source":["MODELS_PATH = \"drive/MyDrive/GRL_Mini_Project/models/uniform_init\" # TODO os.sep\n","\n","def gnn_file_name(model_type, params, idx):\n","  if model_type == \"GCN\":\n","    gcn_channels = \"_\".join(str(c) for c in params[\"gcn_channels\"])\n","    num_gcn_layers = params[\"num_gcn_layers\"]\n","    gcn_act = params[\"gcn_name\"]\n","    pooling = params[\"pooling_name\"]\n","    mlp_channels = \"_\".join(str(c) for c in params[\"mlp_channels\"])\n","    num_mlp_layers = params[\"num_mlp_layers\"]\n","    mlp_act = params[\"mlp_name\"]\n","    final_act = params[\"final_name\"]\n","    num_features = params[\"num_features\"]\n","\n","    return os.sep.join([\n","        MODELS_PATH, \"_\".join([\n","            str(num_features), gcn_channels, str(num_gcn_layers), gcn_act,\n","            pooling, mlp_channels, str(num_mlp_layers), mlp_act, final_act\n","        ]), str(idx) + \".pt\"\n","    ])\n","\n","  else:\n","    raise ValueError(f\"Cannot recognise GNN type {model_type}\")\n","\n","print(gnn_file_name(\n","    \"GCN\", {\"gcn_channels\":(10, 10, 2), \"num_gcn_layers\":3, \"pooling_name\":\"mean\",\n","   \"gcn_name\":\"clipped_relu\", \"mlp_channels\":(3, 1), \"num_mlp_layers\":2,\n","    \"mlp_name\":\"tanh\", \"final_name\":\"sigmoid\", \"num_features\":10\n","}, idx=1))"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1704865407572,"user":{"displayName":"Leo Bujdei-Leonte","userId":"14269380342128481548"},"user_tz":0},"id":"LwxfWmHD4fwN"},"outputs":[],"source":["import pathlib\n","\n","def generate_models(params):\n","  file_name = gnn_file_name(\"GCN\", params, idx=0)\n","  file_name = os.sep.join(file_name.split(os.sep)[:-1])\n","  if (not os.path.isdir(file_name)):\n","    pathlib.Path(file_name).mkdir(parents=True, exist_ok=True)\n","    print(\"Generated parent folder\", file_name)\n","\n","  models = []\n","  for i in range(params[\"num_models\"]):\n","    file_name = gnn_file_name(\"GCN\", params, idx=i)\n","    if (os.path.isfile(file_name)):\n","      model = torch.load(file_name)\n","    else:\n","      model = GCN(\n","          gcn_channels=params[\"gcn_channels\"], num_gcn_layers=params[\"num_gcn_layers\"], gcn_act=params[\"gcn_act\"],\n","          pooling=params[\"pooling\"], mlp_channels=params[\"mlp_channels\"],\n","          num_mlp_layers=params[\"num_mlp_layers\"], mlp_act=params[\"mlp_act\"], final_act=params[\"final_act\"]\n","      ).to(device)\n","      torch.save(model, file_name)\n","      print(f\"Generated model {i+1}/{params['num_models']}\")\n","    models.append(model)\n","  print(\"Initialised all models.\")\n","  return models"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1704865407572,"user":{"displayName":"Leo Bujdei-Leonte","userId":"14269380342128481548"},"user_tz":0},"id":"iq7ainJpawlA"},"outputs":[],"source":["def check_valid_files(params, data_params):\n","  i, j = 0, 0\n","  for num_nodes in data_params[\"nums_nodes\"]:\n","    for subtype in data_params[\"subtypes\"]:\n","      for idx in range(data_params[\"num_graphs\"]):\n","        file_name = graph_file_name(\n","            mode=data_params[\"mode\"],\n","            num_nodes=num_nodes,\n","            p_edge=subtype_probs.get(subtype, lambda _: None)(num_nodes),\n","            num_features=params[\"num_features\"],\n","            subtype=subtype,\n","            idx=idx,\n","        )\n","        j += 1\n","        if (not os.path.isfile(file_name)):\n","          print(f\"Failed to locate\", file_name)\n","          i += 1\n","  if (i):\n","    print(f\"Failed to locate {i} out of {j} necessary files.\")\n","    return False\n","  else:\n","    print(f\"Found all {j} necessary files.\")\n","    return True"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1704865407573,"user":{"displayName":"Leo Bujdei-Leonte","userId":"14269380342128481548"},"user_tz":0},"id":"u71bLr4uhDAG"},"outputs":[],"source":["from random import shuffle\n","import gc\n","from itertools import product\n","\n","def test(models, params, data_params):\n","  keys = list(product(data_params[\"nums_nodes\"], data_params[\"subtypes\"], range(data_params[\"num_graphs\"])))\n","  shuffle(keys) # to decrease GPU RAM load; less chance of a crash due to garbage collector falling behind\n","\n","  count = 0\n","  results = [{} for _ in range(params[\"num_models\"])]\n","  for num_nodes, subtype, idx in keys:\n","    file_name = graph_file_name(\n","        mode=data_params[\"mode\"],\n","        num_nodes=num_nodes,\n","        p_edge=subtype_probs.get(subtype, lambda _: None)(num_nodes),\n","        num_features=params[\"num_features\"],\n","        subtype=subtype,\n","        idx=idx,\n","    )\n","\n","    g = torch.load(file_name)\n","    for i, model in enumerate(models):\n","      if (num_nodes, subtype) not in results[i]:\n","        results[i][(num_nodes, subtype)] = []\n","      results[i][(num_nodes, subtype)].append(1 if model(g.x, g.edge_index) >= 0.5 else 0)\n","      if (num_nodes >= 1000):\n","        gc.collect()\n","    if (num_nodes >= 1000):\n","      del g\n","      gc.collect()\n","\n","    count += 1\n","    if (count % 10 == 0):\n","      print(f\"Iteration {count}/{len(keys)} passed\")\n","  return results"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1704865407573,"user":{"displayName":"Leo Bujdei-Leonte","userId":"14269380342128481548"},"user_tz":0},"id":"p5RAT-ohoucL"},"outputs":[],"source":["import traceback\n","from datetime import datetime\n","\n","def run_full_test(params, data_params):\n","  results = None\n","\n","  try:\n","    models = generate_models(params)\n","    if check_valid_files(params, data_params):\n","      results = test(models, params, data_params)\n","  except KeyboardInterrupt:\n","    return\n","  except Exception:\n","    print(\"Something went wrong!\")\n","    trace = traceback.format_exc()\n","    print(trace)\n","    with open(\"drive/MyDrive/GRL_Mini_Project/error.txt\", \"a\") as f:\n","      f.write(\"\\n\".join([\n","          \"Test with parameters:\" , \"\\t\" + params.__str__(), \"\\t\" +\n","          data_params.__str__(), \"raised exception:\", trace, \"\\n\\n\"\n","      ]))\n","\n","  if results:\n","    mean_results = [{} for _ in range(params[\"num_models\"])]\n","    for num_nodes, subtype in product(data_params[\"nums_nodes\"], data_params[\"subtypes\"]):\n","      for i in range(params[\"num_models\"]):\n","        mean_results[i][(num_nodes, subtype)] = sum(results[i][(num_nodes, subtype)]) / data_params[\"num_graphs\"]\n","\n","    with open(\"drive/MyDrive/GRL_Mini_Project/results_uniform_final.txt\", \"a\") as f:\n","      f.write(\"\\n\".join([str(datetime.now()), params.__str__(), data_params.__str__(), mean_results.__str__(), \"\\n\\n\"]))\n","    print(\"Finished test.\")"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1704865407574,"user":{"displayName":"Leo Bujdei-Leonte","userId":"14269380342128481548"},"user_tz":0},"id":"oteC42hoyvWL"},"outputs":[],"source":["params_one_clipped_mean = {\n","    \"model_name\": \"GCN\",\n","    \"num_models\": 10,\n","    \"num_features\": 10, # deprecated\n","    \"gcn_channels\": (10, 10), # first value must equal num_features\n","    \"num_gcn_layers\": 1,\n","    \"gcn_act\": ClippedReLU().apply,\n","    \"gcn_name\": \"clipped_relu\",\n","    \"pooling\": geom_nn.pool.global_mean_pool,\n","    \"pooling_name\": \"mean\",\n","    \"mlp_channels\": (10, 1), # do not change\n","    \"num_mlp_layers\": 2, # do not change\n","    \"mlp_act\": nn.Tanh(), # do not change\n","    \"mlp_name\": \"tanh\", # do not change\n","    \"final_act\": nn.Sigmoid(), # do not change\n","    \"final_name\": \"sigmoid\", # do not change\n","}\n","\n","params_two_clipped_mean = {\n","    \"model_name\": \"GCN\",\n","    \"num_models\": 10,\n","    \"num_features\": 10, # deprecated\n","    \"gcn_channels\": (10, 10), # first value must equal num_features\n","    \"num_gcn_layers\": 2,\n","    \"gcn_act\": ClippedReLU().apply,\n","    \"gcn_name\": \"clipped_relu\",\n","    \"pooling\": geom_nn.pool.global_mean_pool,\n","    \"pooling_name\": \"mean\",\n","    \"mlp_channels\": (10, 1), # do not change\n","    \"num_mlp_layers\": 2, # do not change\n","    \"mlp_act\": nn.Tanh(), # do not change\n","    \"mlp_name\": \"tanh\", # do not change\n","    \"final_act\": nn.Sigmoid(), # do not change\n","    \"final_name\": \"sigmoid\", # do not change\n","}\n","\n","params_three_clipped_mean = {\n","    \"model_name\": \"GCN\",\n","    \"num_models\": 10,\n","    \"num_features\": 10, # deprecated\n","    \"gcn_channels\": (10, 10), # first value must equal num_features\n","    \"num_gcn_layers\": 3,\n","    \"gcn_act\": ClippedReLU().apply,\n","    \"gcn_name\": \"clipped_relu\",\n","    \"pooling\": geom_nn.pool.global_mean_pool,\n","    \"pooling_name\": \"mean\",\n","    \"mlp_channels\": (10, 1), # do not change\n","    \"num_mlp_layers\": 2, # do not change\n","    \"mlp_act\": nn.Tanh(), # do not change\n","    \"mlp_name\": \"tanh\", # do not change\n","    \"final_act\": nn.Sigmoid(), # do not change\n","    \"final_name\": \"sigmoid\", # do not change\n","}\n","\n","params_one_relu_mean = {\n","    \"model_name\": \"GCN\",\n","    \"num_models\": 10,\n","    \"num_features\": 10, # deprecated\n","    \"gcn_channels\": (10, 10), # first value must equal num_features\n","    \"num_gcn_layers\": 1,\n","    \"gcn_act\": nn.ReLU(),\n","    \"gcn_name\": \"relu\",\n","    \"pooling\": geom_nn.pool.global_mean_pool,\n","    \"pooling_name\": \"mean\",\n","    \"mlp_channels\": (10, 1), # do not change\n","    \"num_mlp_layers\": 2, # do not change\n","    \"mlp_act\": nn.Tanh(), # do not change\n","    \"mlp_name\": \"tanh\", # do not change\n","    \"final_act\": nn.Sigmoid(), # do not change\n","    \"final_name\": \"sigmoid\", # do not change\n","}\n","\n","params_two_relu_mean = {\n","    \"model_name\": \"GCN\",\n","    \"num_models\": 10,\n","    \"num_features\": 10, # deprecated\n","    \"gcn_channels\": (10, 10), # first value must equal num_features\n","    \"num_gcn_layers\": 2,\n","    \"gcn_act\": nn.ReLU(),\n","    \"gcn_name\": \"relu\",\n","    \"pooling\": geom_nn.pool.global_mean_pool,\n","    \"pooling_name\": \"mean\",\n","    \"mlp_channels\": (10, 1), # do not change\n","    \"num_mlp_layers\": 2, # do not change\n","    \"mlp_act\": nn.Tanh(), # do not change\n","    \"mlp_name\": \"tanh\", # do not change\n","    \"final_act\": nn.Sigmoid(), # do not change\n","    \"final_name\": \"sigmoid\", # do not change\n","}\n","\n","params_three_relu_mean = {\n","    \"model_name\": \"GCN\",\n","    \"num_models\": 10,\n","    \"num_features\": 10, # deprecated\n","    \"gcn_channels\": (10, 10), # first value must equal num_features\n","    \"num_gcn_layers\": 3,\n","    \"gcn_act\": nn.ReLU(),\n","    \"gcn_name\": \"relu\",\n","    \"pooling\": geom_nn.pool.global_mean_pool,\n","    \"pooling_name\": \"mean\",\n","    \"mlp_channels\": (10, 1), # do not change\n","    \"num_mlp_layers\": 2, # do not change\n","    \"mlp_act\": nn.Tanh(), # do not change\n","    \"mlp_name\": \"tanh\", # do not change\n","    \"final_act\": nn.Sigmoid(), # do not change\n","    \"final_name\": \"sigmoid\", # do not change\n","}\n","\n","params_one_clipped_sum = {\n","    \"model_name\": \"GCN\",\n","    \"num_models\": 10,\n","    \"num_features\": 10, # deprecated\n","    \"gcn_channels\": (10, 10), # first value must equal num_features\n","    \"num_gcn_layers\": 1,\n","    \"gcn_act\": ClippedReLU().apply,\n","    \"gcn_name\": \"clipped_relu\",\n","    \"pooling\": geom_nn.pool.global_add_pool,\n","    \"pooling_name\": \"sum\",\n","    \"mlp_channels\": (10, 1), # do not change\n","    \"num_mlp_layers\": 2, # do not change\n","    \"mlp_act\": nn.Tanh(), # do not change\n","    \"mlp_name\": \"tanh\", # do not change\n","    \"final_act\": nn.Sigmoid(), # do not change\n","    \"final_name\": \"sigmoid\", # do not change\n","}\n","\n","params_two_clipped_sum = {\n","    \"model_name\": \"GCN\",\n","    \"num_models\": 10,\n","    \"num_features\": 10, # deprecated\n","    \"gcn_channels\": (10, 10), # first value must equal num_features\n","    \"num_gcn_layers\": 2,\n","    \"gcn_act\": ClippedReLU().apply,\n","    \"gcn_name\": \"clipped_relu\",\n","    \"pooling\": geom_nn.pool.global_add_pool,\n","    \"pooling_name\": \"sum\",\n","    \"mlp_channels\": (10, 1), # do not change\n","    \"num_mlp_layers\": 2, # do not change\n","    \"mlp_act\": nn.Tanh(), # do not change\n","    \"mlp_name\": \"tanh\", # do not change\n","    \"final_act\": nn.Sigmoid(), # do not change\n","    \"final_name\": \"sigmoid\", # do not change\n","}\n","\n","params_three_clipped_sum = {\n","    \"model_name\": \"GCN\",\n","    \"num_models\": 10,\n","    \"num_features\": 10, # deprecated\n","    \"gcn_channels\": (10, 10), # first value must equal num_features\n","    \"num_gcn_layers\": 3,\n","    \"gcn_act\": ClippedReLU().apply,\n","    \"gcn_name\": \"clipped_relu\",\n","    \"pooling\": geom_nn.pool.global_add_pool,\n","    \"pooling_name\": \"sum\",\n","    \"mlp_channels\": (10, 1), # do not change\n","    \"num_mlp_layers\": 2, # do not change\n","    \"mlp_act\": nn.Tanh(), # do not change\n","    \"mlp_name\": \"tanh\", # do not change\n","    \"final_act\": nn.Sigmoid(), # do not change\n","    \"final_name\": \"sigmoid\", # do not change\n","}"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1704865407574,"user":{"displayName":"Leo Bujdei-Leonte","userId":"14269380342128481548"},"user_tz":0},"id":"UKHIVHwjCQ5I"},"outputs":[],"source":["data_params_er = {\n","  \"mode\": GenerationMode.ER,\n","  \"nums_nodes\": [10, 50, 100, 500, 1000, 5000],\n","  \"subtypes\": [\"regular\", \"sparse\", \"very_sparse\"],\n","  \"num_graphs\": 32,\n","}\n","\n","data_params_er_no_regular = {\n","  \"mode\": GenerationMode.ER,\n","  \"nums_nodes\": [10, 50, 100, 500, 1000, 5000],\n","  \"subtypes\": [\"sparse\", \"very_sparse\"],\n","  \"num_graphs\": 32,\n","}\n","\n","data_params_sbm = {\n","    \"mode\": GenerationMode.SBM,\n","    \"nums_nodes\": [10, 50, 100, 500, 1000, 5000],\n","    \"subtypes\": [\"few_dense_in\", \"few_dense_out\", \"many_dense_in\", \"many_dense_out\"],\n","    \"num_graphs\": 32,\n","}\n","\n","data_params_ba = {\n","    \"mode\": GenerationMode.BA,\n","    \"nums_nodes\": [10, 50, 100, 500, 1000, 5000],\n","    \"subtypes\": [\"dense\", \"sparse\", \"very sparse\"],\n","    \"num_graphs\": 32\n","}"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"xKwzplf1BWtn","executionInfo":{"status":"ok","timestamp":1704865407575,"user_tz":0,"elapsed":19,"user":{"displayName":"Leo Bujdei-Leonte","userId":"14269380342128481548"}}},"outputs":[],"source":["all_params = [params_one_clipped_mean, params_two_clipped_mean, params_three_clipped_mean,\n","              params_one_relu_mean, params_two_relu_mean, params_three_relu_mean,\n","              params_one_clipped_sum, params_two_clipped_sum, params_three_clipped_sum]\n","\n","all_data = [data_params_er, data_params_sbm, data_params_ba]"]},{"cell_type":"code","source":["run_full_test(params_one_relu_mean, data_params_er)\n","# run_full_test(params_three_clipped_mean, data_params_er)\n","# run_full_test(params_three_clipped_mean, data_params_sbm)\n","# run_full_test(params_three_clipped_mean, data_params_ba)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ieJOA53xdg2K","executionInfo":{"status":"ok","timestamp":1704868208535,"user_tz":0,"elapsed":303674,"user":{"displayName":"Leo Bujdei-Leonte","userId":"14269380342128481548"}},"outputId":"9be2f889-bb65-44ba-d5fb-2a8fbb6ff97e"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Initialised all models.\n","Found all 576 necessary files.\n","Iteration 10/576 passed\n","Iteration 20/576 passed\n","Iteration 30/576 passed\n","Iteration 40/576 passed\n","Iteration 50/576 passed\n","Iteration 60/576 passed\n","Iteration 70/576 passed\n","Iteration 80/576 passed\n","Iteration 90/576 passed\n","Iteration 100/576 passed\n","Iteration 110/576 passed\n","Iteration 120/576 passed\n","Iteration 130/576 passed\n","Iteration 140/576 passed\n","Iteration 150/576 passed\n","Iteration 160/576 passed\n","Iteration 170/576 passed\n","Iteration 180/576 passed\n","Iteration 190/576 passed\n","Iteration 200/576 passed\n","Iteration 210/576 passed\n","Iteration 220/576 passed\n","Iteration 230/576 passed\n","Iteration 240/576 passed\n","Iteration 250/576 passed\n","Iteration 260/576 passed\n","Iteration 270/576 passed\n","Iteration 280/576 passed\n","Iteration 290/576 passed\n","Iteration 300/576 passed\n","Iteration 310/576 passed\n","Iteration 320/576 passed\n","Iteration 330/576 passed\n","Iteration 340/576 passed\n","Iteration 350/576 passed\n","Iteration 360/576 passed\n","Iteration 370/576 passed\n","Iteration 380/576 passed\n","Iteration 390/576 passed\n","Iteration 400/576 passed\n","Iteration 410/576 passed\n","Iteration 420/576 passed\n","Iteration 430/576 passed\n","Iteration 440/576 passed\n","Iteration 450/576 passed\n","Iteration 460/576 passed\n","Iteration 470/576 passed\n","Iteration 480/576 passed\n","Iteration 490/576 passed\n","Iteration 500/576 passed\n","Iteration 510/576 passed\n","Iteration 520/576 passed\n","Iteration 530/576 passed\n","Iteration 540/576 passed\n","Iteration 550/576 passed\n","Iteration 560/576 passed\n","Iteration 570/576 passed\n","Finished test.\n"]}]},{"cell_type":"code","source":["from torch_geometric.datasets import TUDataset\n","from torch_geometric.datasets import Reddit\n","from torch_geometric.datasets import PCQM4Mv2\n","\n","def test_real_dataset(params, dataset):\n","  models = generate_models(params)\n","\n","  old_num_features = dataset[0].x.shape[1]\n","  padding = params[\"num_features\"] - old_num_features\n","  if (padding < 0):\n","    raise NotImplementedError()\n","\n","  res = [[] for _ in range(params[\"num_models\"])]\n","  for data in dataset:\n","    x = nn.functional.pad(data.x, (0, padding, 0, 0), mode=\"constant\", value=0).to(device)\n","    edge_index = data.edge_index.to(device)\n","\n","    for idx, model in enumerate(models):\n","      res[idx].append(1 if model(x, edge_index) >= 0.5 else 0)\n","\n","  mean_res = [sum(r) / len(r) for r in res]\n","  formatted_results = \", \".join([str(int(r * 100)) + \"%\" for r in mean_res])\n","  ans = f\"{dataset.name} dataset with initial embedding size {old_num_features} \"\n","  if (padding > 0):\n","    ans += f\"lifted \"\n","  else:\n","    ans += f\"clipped \"\n","  ans += f\"to {params['num_features']} classifies as: [{formatted_results}]\"\n","  print(ans)\n","\n","\n","# test_real_dataset(params_three_relu_mean, TUDataset(root=\"/tmp/ENZYMES\", name=\"ENZYMES\"))"],"metadata":{"id":"73yg4zkpv5m1","executionInfo":{"status":"ok","timestamp":1704867225071,"user_tz":0,"elapsed":58,"user":{"displayName":"Leo Bujdei-Leonte","userId":"14269380342128481548"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# from torch_geometric.datasets import GNNBenchmarkDataset\n","\n","# dataset = TUDataset(root=\"/tmp/MUTAG\", name=\"MUTAG\")\n","# print(len(dataset))\n","# print(dataset[0])\n","# num_features = 7\n","# model = GCN((num_features, num_features), 2, ClippedReLU().apply, geom_nn.pool.global_mean_pool,\n","#             (num_features, 1), 2, nn.Tanh(), nn.Sigmoid())\n","# for layer in model.mlp:\n","#   layer.requires_grad = False"],"metadata":{"id":"vsJ-zZ8H2C1O","executionInfo":{"status":"ok","timestamp":1704867225072,"user_tz":0,"elapsed":25,"user":{"displayName":"Leo Bujdei-Leonte","userId":"14269380342128481548"}}},"execution_count":17,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"mount_file_id":"1ptjjP0afKvMCSRJ9Ct0s5Y-lPiY6jj1p","authorship_tag":"ABX9TyPKSpshT+E39+ejDOaAukcf"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}